# 📊 Challenge TelecomX - Parte 2

Este proyecto forma parte del **Challenge de Data Science LATAM (Alura)** y corresponde a la segunda etapa del reto.  
El objetivo principal es realizar la **extracción, transformación, carga (ETL)** y **análisis exploratorio de datos** para generar insights que apoyen la toma de decisiones.

---

## 📌 Descripción

El proyecto toma como base los datos de **clientes de TelecomX** y se centra en:

- Limpieza y preprocesamiento de datos.
- Análisis exploratorio (EDA).
- Creación de visualizaciones para identificar patrones.
- Preparación de datos para un modelo de **Machine Learning**.
- Generación de un informe final.

---

## ⚙️ Requisitos

Asegúrate de tener instalado **Python 3.9+** y las siguientes librerías:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn jupyter
```

---

## 🚀 Ejecución

1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu_usuario/challenge-telecomx.git
   cd challenge-telecomx
   ```

2. Si deseas correr el **notebook**:
   ```bash
   jupyter notebook Challenge_TelecomX_Parte_2.ipynb
   ```

3. Si prefieres correrlo como **script**:
   ```bash
   python Challenge_TelecomX_Parte_2.py
   ```

---

## 📊 Flujo de trabajo

El proyecto sigue la secuencia:

1. **Importación de librerías**  
2. **Carga de datos**  
3. **Exploración inicial** (shape, tipos de datos, nulos, duplicados)  
4. **Transformaciones** (ETL: limpieza, encoding, normalización, etc.)  
5. **Visualización** (gráficas de distribución, correlación, etc.)  
6. **Modelado preliminar** (si aplica)  
7. **Conclusiones e insights**

---

## 📂 Estructura del proyecto

```
📁 challenge-telecomx
│── 📄 Challenge_TelecomX_Parte_2.ipynb   # Notebook principal
│── 📄 Challenge_TelecomX_Parte_2.py      # Script exportado
│── 📄 README.md                          # Documentación del proyecto
│── 📂 data/                              # Carpeta para datasets
│── 📂 outputs/                           # Gráficas y resultados
```

---

## ✨ Autor

Proyecto desarrollado por **[Tu Nombre]** en el marco del **Challenge de Data Science LATAM (Alura)**.
